{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNG/bCMIqoJezrK33I69/Of",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cd-public/coluda/blob/main/GPU_CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ref](https://www.geeksforgeeks.org/how-to-run-cuda-c-c-on-jupyter-notebook-in-google-colaboratory/)"
      ],
      "metadata": {
        "id": "1rhyMumB4M_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "A09VLdt94RuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b26631ac-e9aa-42fe-d529-df62c672396b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc3yHzf86Rzx",
        "outputId": "87d181a4-9016-4445-b988-f8d2d22d8adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku42L6lh6Vu3",
        "outputId": "fcab3e4d-793d-43c2-f795-d3f3988f0e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp_ryjq1yt\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "int main() {\n",
        "    cout << \"Gee you later.\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIRgWqmi6eZ-",
        "outputId": "526d66ba-cd64-4d22-bfb2-65c0d15be788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gee you later.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWaDE4VRf8Rw",
        "outputId": "7d27735d-13c1-439f-9a31-593951ae80d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 18 02:51:07 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z_AmHkvIfGI",
        "outputId": "d3733394-defc-4b59-b4ab-323dbdc0c44c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ref](https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/)"
      ],
      "metadata": {
        "id": "YWuvXz8d7YDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void cuda_hello(){\n",
        "    printf(\"Hello World from GPU!\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    cuda_hello<<<1,1>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wyu7zaT_J3mT",
        "outputId": "76aa733d-5e03-4ec5-964a-f7846987c403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from GPU!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#define N 5\n",
        "\n",
        "void vector_add(float *out, float *a, float *b, int n) {\n",
        "    for(int i = 0; i < n; i++){\n",
        "        out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *a, *b, *out;\n",
        "\n",
        "    // Allocate memory\n",
        "    a   = (float*)malloc(sizeof(float) * N);\n",
        "    b   = (float*)malloc(sizeof(float) * N);\n",
        "    out = (float*)malloc(sizeof(float) * N);\n",
        "\n",
        "    // Initialize host arrays\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = i * 1.0f;\n",
        "        b[i] = i * 2.0f;\n",
        "    }\n",
        "\n",
        "    // Main function\n",
        "    vector_add(out, a, b, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    printf(\"%f\\n\", out[N/2]);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SoDi8xUKY8J",
        "outputId": "49d15938-1c47-41ea-f759-cb2757b521c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.000000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#define N 5\n",
        "\n",
        "\n",
        "__global__ void vector_add(float *out, float *a, float *b, int n) {\n",
        "    for(int i = 0; i < n; i ++){\n",
        "        out[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    float *a, *b, *out;\n",
        "    float *d_a, *d_b, *d_out;\n",
        "\n",
        "    // Allocate host memory\n",
        "    a   = (float*)malloc(sizeof(float) * N);\n",
        "    b   = (float*)malloc(sizeof(float) * N);\n",
        "    out = (float*)malloc(sizeof(float) * N);\n",
        "\n",
        "    // Initialize host arrays\n",
        "    for(int i = 0; i < N; i++){\n",
        "        a[i] = i * 1.0f;\n",
        "        b[i] = i * 2.0f;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc((void**)&d_a, sizeof(float) * N);\n",
        "    cudaMalloc((void**)&d_b, sizeof(float) * N);\n",
        "    cudaMalloc((void**)&d_out, sizeof(float) * N);\n",
        "\n",
        "    // Transfer data from host to device memory\n",
        "    cudaMemcpy(d_a, a, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Executing kernel\n",
        "    vector_add<<<1,1>>>(d_out, d_a, d_b, N);\n",
        "\n",
        "    // Transfer data back to host memory\n",
        "    cudaMemcpy(out, d_out, sizeof(float) * N, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Cleanup after kernel execution\n",
        "    printf(\"back\\n\");\n",
        "    printf(\"out[N/2] is %f, a[N/2] + b[N/2] is %f\\n\", out[N/2], a[N/2] + b[N/2]);\n",
        "\n",
        "    // Deallocate device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_out);\n",
        "\n",
        "    // Deallocate host memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(out);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-ZbGhcrLjdb",
        "outputId": "5a222468-b287-408e-cb27-dcb778b82c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "back\n",
            "out[N/2] is 6.000000, a[N/2] + b[N/2] is 6.000000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}